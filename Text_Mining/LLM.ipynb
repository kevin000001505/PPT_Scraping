{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect the MySQL database ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = mysql.connector.connect(\n",
    "            host='localhost',\n",
    "            user='root',\n",
    "            password='password',\n",
    "            database='PPT'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\" SELECT * FROM posts_details\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xp/1gy0dsh531s017q00bdzwmgw0000gn/T/ipykernel_80978/1848774206.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, connection)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Re: [問卦] 以前當兵都是一起洗澡的嗎？？？</td>\n",
       "      <td>ai2311 ()</td>\n",
       "      <td>Fri Apr 19 21:18:58 2024</td>\n",
       "      <td>['※ 引述《gn505250 (dwas356916)》之銘言：', ': 聽說以前當兵都...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[問卦] 你們股票都有賺到吧？</td>\n",
       "      <td>opemhood (大漢堡)</td>\n",
       "      <td>Fri Apr 19 21:21:24 2024</td>\n",
       "      <td>欸欸最近八年來，股市一直破新高這八年，鄉民都有賺到錢吧？一定有賺到錢吧？有沒有這方面的八卦？--</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[問卦] 歸０是什麼感覺</td>\n",
       "      <td>vigle5566 (威哥)</td>\n",
       "      <td>Fri Apr 19 21:20:11 2024</td>\n",
       "      <td>搭給賀 我天橋下肥宅拉阿肥友人是一位玩遊戲會怒吼亂搓的豬角色的操控很弱 技能使出來的叭叭會被...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[問卦] 凱格爾訓練機幹嘛用的？</td>\n",
       "      <td>cowardlyman (有功夫無懦夫)</td>\n",
       "      <td>Fri Apr 19 21:17:50 2024</td>\n",
       "      <td>本肥被推薦購買這個東西這個東西是要訓練什麼看那顆球的位置是要訓練肛門讓括約肌變有力嗎？有卦嗎？--</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[問卦] 台灣空軍飛官,有人遇過UFO嗎?</td>\n",
       "      <td>lelena (太陽神-RA)</td>\n",
       "      <td>Fri Apr 19 21:17:26 2024</td>\n",
       "      <td>遇到UFO的飛行員,都是國外的飛行員,台灣飛行員也是每天在空中飛,不知道有沒有台灣飛官遇過不...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                     title                author  \\\n",
       "0   1  Re: [問卦] 以前當兵都是一起洗澡的嗎？？？             ai2311 ()   \n",
       "1   2           [問卦] 你們股票都有賺到吧？        opemhood (大漢堡)   \n",
       "2   3              [問卦] 歸０是什麼感覺        vigle5566 (威哥)   \n",
       "3   4          [問卦] 凱格爾訓練機幹嘛用的？  cowardlyman (有功夫無懦夫)   \n",
       "4   5     [問卦] 台灣空軍飛官,有人遇過UFO嗎?       lelena (太陽神-RA)   \n",
       "\n",
       "                       date  \\\n",
       "0  Fri Apr 19 21:18:58 2024   \n",
       "1  Fri Apr 19 21:21:24 2024   \n",
       "2  Fri Apr 19 21:20:11 2024   \n",
       "3  Fri Apr 19 21:17:50 2024   \n",
       "4  Fri Apr 19 21:17:26 2024   \n",
       "\n",
       "                                             content comments  \n",
       "0  ['※ 引述《gn505250 (dwas356916)》之銘言：', ': 聽說以前當兵都...           \n",
       "1   欸欸最近八年來，股市一直破新高這八年，鄉民都有賺到錢吧？一定有賺到錢吧？有沒有這方面的八卦？--           \n",
       "2  搭給賀 我天橋下肥宅拉阿肥友人是一位玩遊戲會怒吼亂搓的豬角色的操控很弱 技能使出來的叭叭會被...           \n",
       "3  本肥被推薦購買這個東西這個東西是要訓練什麼看那顆球的位置是要訓練肛門讓括約肌變有力嗎？有卦嗎？--           \n",
       "4  遇到UFO的飛行員,都是國外的飛行員,台灣飛行員也是每天在空中飛,不知道有沒有台灣飛官遇過不...           "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install NLP model transalte chinese to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01547af47df40a1a905c3f06baf21e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/3.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29fe8f3cab02441c8a90f9d4b723daec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8868c94442b4218b84913fb73295fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'These waste countries do not really waste time.'}]\n"
     ]
    }
   ],
   "source": [
    "# first version example\n",
    "from transformers import pipeline\n",
    "\n",
    "# 创建翻译 pipeline，指定模型\n",
    "translator = pipeline(\"translation\", model=\"facebook/m2m100_418M\")\n",
    "# 输入中文文本，进行翻译\n",
    "chinese_text = \"這些垃圾國家美國真的不用浪費時間\"\n",
    "translated_text = translator(chinese_text, src_lang=\"zh\", tgt_lang=\"en\")\n",
    "\n",
    "# 输出翻译后的英文文本\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model\n",
    "#from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "\n",
    "# Define the model and tokenizer\n",
    "#model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "#tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
    "#model.save_pretrained('./NLP_Translate_Model/m2m100_418M_model')\n",
    "#tokenizer.save_pretrained('./NLP_Translate_Model/m2m100_418M_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "\n",
    "# Load the model and tokenizer from local directory\n",
    "model = M2M100ForConditionalGeneration.from_pretrained('./NLP_Translate_Model/m2m100_418M_model')\n",
    "tokenizer = M2M100Tokenizer.from_pretrained('./NLP_Translate_Model/m2m100_418M_tokenizer')\n",
    "\n",
    "# Create a translation pipeline using the local model and tokenizer\n",
    "translator = pipeline(\"translation\", model=model, tokenizer=tokenizer)\n",
    "def translate(text):\n",
    "    # Input Chinese text and translate\n",
    "    chinese_text = text\n",
    "    translated_text = translator(chinese_text, src_lang=\"zh\", tgt_lang=\"en\")\n",
    "\n",
    "    # Output the translated English text\n",
    "    return translated_text[0]['translation_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the last eight years, the stock market has broken up these eight years, the country’s people have earned money, right?\n"
     ]
    }
   ],
   "source": [
    "chinese_text = \"欸欸最近八年來，股市一直破新高這八年，鄉民都有賺到錢吧？一定有賺到錢吧？有沒有這方面的八卦？\"\n",
    "translate_chinese_text = translate(chinese_text)\n",
    "print(translate_chinese_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model\n",
    "#from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "\n",
    "# Define the model and tokenizer\n",
    "#model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "#tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Save the model and tokenizer locally\n",
    "#model.save_pretrained('./NLP_Sentiment_Analysis/sentiment_analysis_model')\n",
    "#tokenizer.save_pretrained('./NLP_Sentiment_Analysis/sentiment_analysis_tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "\n",
    "# Load the model and tokenizer from local directory\n",
    "model = DistilBertForSequenceClassification.from_pretrained('./NLP_Sentiment_Analysis/sentiment_analysis_model')\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('./NLP_Sentiment_Analysis/sentiment_analysis_tokenizer')\n",
    "\n",
    "# Create a sentiment analysis pipeline using the local model and tokenizer\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Input text (assuming `translated_text` is the output from your translation pipeline)\n",
    "def sentiment_analysis(text):\n",
    "    print(text)\n",
    "    return classifier(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the last eight years, the stock market has broken up these eight years, the country’s people have earned money, right?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9662074446678162}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis(translated_text[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add new Column for the sentiment analysis result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_content(text):\n",
    "    text = re.sub(r\"[^\\u4e00-\\u9fff\\d.a-zA-Z%+\\-。！？，、；：（）【】《》“”‘’]\", '', text)  # 去除特殊字符\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content summarize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
