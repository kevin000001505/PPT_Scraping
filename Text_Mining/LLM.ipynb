{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect the MySQL database ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = mysql.connector.connect(\n",
    "            host='localhost',\n",
    "            user='root',\n",
    "            password='@America155088',\n",
    "            database='PPT'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\" SELECT * FROM posts_details\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xp/1gy0dsh531s017q00bdzwmgw0000gn/T/ipykernel_80978/1848774206.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, connection)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Re: [問卦] 以前當兵都是一起洗澡的嗎？？？</td>\n",
       "      <td>ai2311 ()</td>\n",
       "      <td>Fri Apr 19 21:18:58 2024</td>\n",
       "      <td>['※ 引述《gn505250 (dwas356916)》之銘言：', ': 聽說以前當兵都...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[問卦] 你們股票都有賺到吧？</td>\n",
       "      <td>opemhood (大漢堡)</td>\n",
       "      <td>Fri Apr 19 21:21:24 2024</td>\n",
       "      <td>欸欸最近八年來，股市一直破新高這八年，鄉民都有賺到錢吧？一定有賺到錢吧？有沒有這方面的八卦？--</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[問卦] 歸０是什麼感覺</td>\n",
       "      <td>vigle5566 (威哥)</td>\n",
       "      <td>Fri Apr 19 21:20:11 2024</td>\n",
       "      <td>搭給賀 我天橋下肥宅拉阿肥友人是一位玩遊戲會怒吼亂搓的豬角色的操控很弱 技能使出來的叭叭會被...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[問卦] 凱格爾訓練機幹嘛用的？</td>\n",
       "      <td>cowardlyman (有功夫無懦夫)</td>\n",
       "      <td>Fri Apr 19 21:17:50 2024</td>\n",
       "      <td>本肥被推薦購買這個東西這個東西是要訓練什麼看那顆球的位置是要訓練肛門讓括約肌變有力嗎？有卦嗎？--</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[問卦] 台灣空軍飛官,有人遇過UFO嗎?</td>\n",
       "      <td>lelena (太陽神-RA)</td>\n",
       "      <td>Fri Apr 19 21:17:26 2024</td>\n",
       "      <td>遇到UFO的飛行員,都是國外的飛行員,台灣飛行員也是每天在空中飛,不知道有沒有台灣飛官遇過不...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                     title                author  \\\n",
       "0   1  Re: [問卦] 以前當兵都是一起洗澡的嗎？？？             ai2311 ()   \n",
       "1   2           [問卦] 你們股票都有賺到吧？        opemhood (大漢堡)   \n",
       "2   3              [問卦] 歸０是什麼感覺        vigle5566 (威哥)   \n",
       "3   4          [問卦] 凱格爾訓練機幹嘛用的？  cowardlyman (有功夫無懦夫)   \n",
       "4   5     [問卦] 台灣空軍飛官,有人遇過UFO嗎?       lelena (太陽神-RA)   \n",
       "\n",
       "                       date  \\\n",
       "0  Fri Apr 19 21:18:58 2024   \n",
       "1  Fri Apr 19 21:21:24 2024   \n",
       "2  Fri Apr 19 21:20:11 2024   \n",
       "3  Fri Apr 19 21:17:50 2024   \n",
       "4  Fri Apr 19 21:17:26 2024   \n",
       "\n",
       "                                             content comments  \n",
       "0  ['※ 引述《gn505250 (dwas356916)》之銘言：', ': 聽說以前當兵都...           \n",
       "1   欸欸最近八年來，股市一直破新高這八年，鄉民都有賺到錢吧？一定有賺到錢吧？有沒有這方面的八卦？--           \n",
       "2  搭給賀 我天橋下肥宅拉阿肥友人是一位玩遊戲會怒吼亂搓的豬角色的操控很弱 技能使出來的叭叭會被...           \n",
       "3  本肥被推薦購買這個東西這個東西是要訓練什麼看那顆球的位置是要訓練肛門讓括約肌變有力嗎？有卦嗎？--           \n",
       "4  遇到UFO的飛行員,都是國外的飛行員,台灣飛行員也是每天在空中飛,不知道有沒有台灣飛官遇過不...           "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install NLP model first\n",
    "#### USing Bert Chinese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db7aaf4c8b947118901abf222ff8717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/880 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf4bc39455d43bbace82177d3c7f543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/409M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ec0e768847477384b76fd5bd2789ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/295 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74bdfd8cd3e44073914d2d3920244d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16724a039c84a0dbb11bfd4b88fa599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer,pipeline\n",
    "model = AutoModelForSequenceClassification.from_pretrained('uer/roberta-base-finetuned-chinanews-chinese')\n",
    "tokenizer = AutoTokenizer.from_pretrained('uer/roberta-base-finetuned-chinanews-chinese')\n",
    "text_classification = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save it in local, so we don't need to install it everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./bert-base-chinese-tokenizer/tokenizer_config.json',\n",
       " './bert-base-chinese-tokenizer/special_tokens_map.json',\n",
       " './bert-base-chinese-tokenizer/vocab.txt',\n",
       " './bert-base-chinese-tokenizer/added_tokens.json',\n",
       " './bert-base-chinese-tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = './bert-base-chinese-model'\n",
    "tokenizer_path = './bert-base-chinese-tokenizer'\n",
    "\n",
    "# 保存模型和分詞器\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_content(text):\n",
    "    text = re.sub(r\"[^\\u4e00-\\u9fff\\d.a-zA-Z%+\\-。！？，、；：（）【】《》“”‘’]\", '', text)  # 去除特殊字符\n",
    "    return text_classification(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf5d435c3bc49cb941bdf54155ac55a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2621afc51a245ed928fb41a3c30bcba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5fd27c7d7ca4318b7e5e15ab8eed3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13649d73e2a475ca553d5792e63a5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafd9a73e2314a7ab49bd4774801a989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c06d7497e84c0fb7bc4d5a3427f490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 130, but your input_length is only 110. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=55)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 鄉民都有賺到錢吧？   有沒有�’方面的八卦 ？ “Youth’s future” is a term used to refer to young people in the United States.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 選擇一個預訓練的摘要模型\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文章內容\n",
    "article = \"\"\"\n",
    "欸欸最近八年來，股市一直破新高這八年，鄉民都有賺到錢吧？一定有賺到錢吧？有沒有這方面的八卦？\n",
    "\"\"\"\n",
    "\n",
    "# 生成摘要\n",
    "summary = summarizer(article, max_length=130, min_length=30, do_sample=False)\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_content(text):\n",
    "    text = re.sub(r\"[^\\u4e00-\\u9fff\\d.a-zA-Z%+\\-。！？，、；：（）【】《》“”‘’]\", '', text) \n",
    "    try:\n",
    "        summary = summarizer(text, max_length=400, min_length=30, do_sample=False)\n",
    "    except IndexError:\n",
    "        return text\n",
    "        \n",
    "    return summary[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建一個TF-IDF Vectorizer對象\n",
    "tfidf = TfidfVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents.append(x for x in df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in df['content']:\n",
    "    text = re.sub(r\"[^\\u4e00-\\u9fff\\d.a-zA-Z%+\\-。！？，、；：（）【】《》“”‘’]\", '', text)\n",
    "    documents.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欸\n",
      "欸\n",
      "最近\n",
      "八年\n",
      "來\n",
      "，\n",
      "股市\n",
      "一直\n",
      "破\n",
      "新高\n",
      "這\n",
      "八年\n",
      "，\n",
      "鄉民\n",
      "都\n",
      "有\n",
      "賺\n",
      "到\n",
      "錢\n",
      "吧\n",
      "？\n",
      "一定\n",
      "有\n",
      "賺\n",
      "到\n",
      "錢\n",
      "吧\n",
      "？\n",
      "有\n",
      "沒\n",
      "有\n",
      "這\n",
      "方面\n",
      "的\n",
      "八卦\n",
      "？\n"
     ]
    }
   ],
   "source": [
    "for token in jieba.cut(\"欸欸最近八年來，股市一直破新高這八年，鄉民都有賺到錢吧？一定有賺到錢吧？有沒有這方面的八卦？\"):\n",
    "    print(token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
